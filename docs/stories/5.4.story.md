# Story 5.4: Azure Functions Testing & Validation

## Status: üü° Ready for Implementation

**Creation Date:** 2025-07-01  
**Story Dependencies:**  
- **Requires:** Story 5.1 (Azure Functions Workspace Migration) ‚úÖ COMPLETED  
- **Requires:** Story 5.2 (Shared Type System Integration) ‚úÖ COMPLETED  
- **Requires:** Story 5.3 (Unified Configuration Management) ‚úÖ COMPLETED  

## Story

**Als Entwickler** m√∂chte ich umfassende Tests f√ºr alle Azure Functions haben, **damit** ich sicherstellen kann, dass die API-Endpunkte korrekt funktionieren, die Konfiguration ordnungsgem√§√ü geladen wird und die Integration mit Azure OpenAI stabil l√§uft.

## Acceptance Criteria

### ‚úÖ Definition of Done
- [ ] **Unit Tests** f√ºr alle Azure Functions (usecases, evaluations, reviewers, results, test-azure-ai)
- [ ] **Integration Tests** f√ºr Azure OpenAI API-Verbindung
- [ ] **Configuration Tests** validieren korrekte Konfigurationsladung
- [ ] **Mocking Infrastructure** f√ºr externe Services (Azure OpenAI, Database)
- [ ] **End-to-End Tests** f√ºr vollst√§ndige API-Workflows
- [ ] **Test Coverage** mindestens 80% f√ºr alle Azure Functions
- [ ] **CI/CD Integration** mit automatischen Tests bei Deployment
- [ ] **Performance Tests** f√ºr API Response Times
- [ ] **Error Handling Tests** f√ºr verschiedene Failure-Szenarien

## Technical Implementation

### Task 1: Test Infrastructure Setup
**Priorit√§t**: Critical  
**Zeitaufwand**: 2 Stunden

Einrichtung der Test-Infrastruktur f√ºr Azure Functions mit Jest und TypeScript.

#### Umsetzung:
```typescript
// packages/testing/jest.config.js
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/src', '<rootDir>/tests'],
  testMatch: ['**/__tests__/**/*.test.ts', '**/?(*.)+(spec|test).ts'],
  collectCoverageFrom: [
    'apps/api/**/*.ts',
    '!apps/api/**/*.d.ts',
    '!apps/api/dist/**',
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80,
    },
  },
  setupFilesAfterEnv: ['<rootDir>/tests/setup.ts']
};
```

#### Files zu erstellen:
- `packages/testing/package.json` - Test package configuration
- `packages/testing/jest.config.js` - Jest configuration  
- `packages/testing/src/mocks/` - Mock utilities f√ºr Azure Services
- `packages/testing/src/fixtures/` - Test data fixtures
- `apps/api/tests/setup.ts` - Test environment setup

### Task 2: Azure Functions Unit Tests
**Priorit√§t**: High  
**Zeitaufwand**: 4 Stunden

Unit Tests f√ºr alle Azure Functions mit Mocking von externen Dependencies.

#### Test Coverage:
```typescript
// apps/api/tests/usecases.test.ts
describe('UseCases API Function', () => {
  describe('GET /usecases', () => {
    it('should return fallback data when database is unavailable')
    it('should return database data when available')
    it('should handle CORS preflight requests')
  })
  
  describe('POST /usecases', () => {
    it('should create new use case with valid data')
    it('should validate required fields')
    it('should handle database errors gracefully')
  })
})

// apps/api/tests/test-azure-ai.test.ts  
describe('Test Azure AI Function', () => {
  describe('Configuration Validation', () => {
    it('should detect missing Azure OpenAI configuration')
    it('should validate complete configuration')
  })
  
  describe('API Integration', () => {
    it('should successfully call Azure OpenAI API')
    it('should handle API errors gracefully')
    it('should respect rate limits')
  })
})
```

#### Files zu erstellen:
- `apps/api/tests/usecases.test.ts` - Use Cases API tests
- `apps/api/tests/evaluations.test.ts` - Evaluations API tests  
- `apps/api/tests/reviewers.test.ts` - Reviewers API tests
- `apps/api/tests/results.test.ts` - Results API tests
- `apps/api/tests/test-azure-ai.test.ts` - Azure AI integration tests

### Task 3: Configuration & Integration Tests
**Priorit√§t**: High  
**Zeitaufwand**: 3 Stunden

Tests f√ºr die shared Configuration und Integration zwischen Frontend und Backend.

#### Test Scenarios:
```typescript
// packages/config/tests/config.test.ts
describe('@ki-usecase-explorer/config', () => {
  describe('loadEnvironmentConfig', () => {
    it('should load default development configuration')
    it('should validate required environment variables')
    it('should handle missing variables gracefully')
  })
  
  describe('getAzureOpenAIConfig', () => {
    it('should return enabled config when all variables present')
    it('should return disabled config when variables missing')
    it('should use correct default API version')
  })
  
  describe('getDatabaseConfig', () => {
    it('should configure logging for development')
    it('should disable logging for production')
    it('should handle missing DATABASE_URL')
  })
})

// apps/api/tests/integration/config-integration.test.ts
describe('Configuration Integration', () => {
  it('should load configuration in Azure Functions context')
  it('should handle environment variable overrides')
  it('should maintain configuration consistency across functions')
})
```

#### Files zu erstellen:
- `packages/config/tests/config.test.ts` - Configuration unit tests
- `apps/api/tests/integration/config-integration.test.ts` - Configuration integration
- `apps/web/tests/api-integration.test.ts` - Frontend-Backend integration tests

### Task 4: Mock Infrastructure for External Services
**Priorit√§t**: Medium  
**Zeitaufwand**: 2 Stunden

Mock-Implementierungen f√ºr Azure OpenAI und Prisma Database f√ºr isolierte Tests.

#### Mock Implementation:
```typescript
// packages/testing/src/mocks/azure-openai.mock.ts
export class AzureOpenAIMock {
  static mockSuccessfulResponse(content: string) {
    return {
      choices: [{ message: { content } }],
      usage: { total_tokens: 100 }
    }
  }
  
  static mockErrorResponse(status: number, message: string) {
    return { error: { status, message } }
  }
}

// packages/testing/src/mocks/prisma.mock.ts
export const prismaMock = {
  useCase: {
    findMany: jest.fn(),
    create: jest.fn(),
    findUnique: jest.fn(),
  },
  evaluation: {
    upsert: jest.fn(),
    findMany: jest.fn(),
    groupBy: jest.fn(),
  },
  reviewer: {
    upsert: jest.fn(),
    findMany: jest.fn(),
  },
}
```

#### Files zu erstellen:
- `packages/testing/src/mocks/azure-openai.mock.ts` - Azure OpenAI API mocks
- `packages/testing/src/mocks/prisma.mock.ts` - Prisma database mocks
- `packages/testing/src/fixtures/use-cases.fixture.ts` - Test data fixtures
- `packages/testing/src/fixtures/evaluations.fixture.ts` - Evaluation test data

### Task 5: End-to-End & Performance Tests
**Priorit√§t**: Medium  
**Zeitaufwand**: 3 Stunden

End-to-End Tests f√ºr komplette Workflows und Performance-Validierung.

#### E2E Test Scenarios:
```typescript
// apps/api/tests/e2e/workflow.test.ts
describe('Complete API Workflow', () => {
  it('should complete full use case evaluation workflow', async () => {
    // 1. Create reviewer
    // 2. Fetch use cases  
    // 3. Submit evaluations
    // 4. Retrieve results
    // 5. Validate aggregated data
  })
  
  it('should handle Azure OpenAI integration end-to-end')
})

// apps/api/tests/performance/api-performance.test.ts
describe('API Performance', () => {
  it('should respond to GET /usecases within 500ms')
  it('should handle 10 concurrent evaluation submissions')
  it('should maintain performance under load')
})
```

#### Files zu erstellen:
- `apps/api/tests/e2e/workflow.test.ts` - End-to-end workflow tests
- `apps/api/tests/performance/api-performance.test.ts` - Performance tests
- `apps/api/tests/e2e/azure-integration.test.ts` - Azure services integration

### Task 6: CI/CD Test Integration
**Priorit√§t**: Medium  
**Zeitaufwand**: 1.5 Stunden

Integration der Tests in CI/CD Pipeline f√ºr automatische Validierung.

#### GitHub Actions Workflow:
```yaml
# .github/workflows/test.yml
name: Test Suite
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
        
      - name: Run configuration validation
        run: npm run validate-config
        
      - name: Run unit tests
        run: npm run test:unit
        
      - name: Run integration tests  
        run: npm run test:integration
        
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

#### Files zu erstellen:
- `.github/workflows/test.yml` - GitHub Actions test workflow
- `scripts/test-ci.sh` - CI test script
- Root package.json test scripts updates

## Implementation Order

### Phase 1: Foundation (2-3 Stunden)
1. **Task 1**: Test Infrastructure Setup
2. **Task 4**: Mock Infrastructure (partial)

### Phase 2: Core Testing (4-5 Stunden)  
3. **Task 2**: Azure Functions Unit Tests
4. **Task 3**: Configuration Tests

### Phase 3: Advanced Testing (4-5 Stunden)
5. **Task 4**: Complete Mock Infrastructure  
6. **Task 5**: E2E & Performance Tests

### Phase 4: Automation (1-2 Stunden)
7. **Task 6**: CI/CD Integration

## Success Metrics

### Coverage Targets
- **Unit Test Coverage**: ‚â• 80% f√ºr alle Azure Functions
- **Integration Test Coverage**: ‚â• 70% f√ºr API-Endpunkte  
- **Configuration Test Coverage**: 100% f√ºr @ki-usecase-explorer/config

### Performance Targets
- **API Response Time**: < 500ms f√ºr GET requests
- **Azure OpenAI Integration**: < 2s f√ºr test requests
- **Database Operations**: < 200ms f√ºr standard queries

### Quality Gates
- ‚úÖ Alle Tests m√ºssen in CI/CD Pipeline bestehen
- ‚úÖ Keine kritischen Sicherheitsl√ºcken in dependencies
- ‚úÖ TypeScript compilation ohne Fehler
- ‚úÖ ESLint ohne Violations

## Dependencies & Blockers

### Internal Dependencies
- ‚úÖ **Story 5.3**: Unified Configuration Management (completed)
- üîÑ **Monorepo Structure**: Shared packages verf√ºgbar

### External Dependencies  
- **Jest & Testing Libraries**: @types/jest, jest, ts-jest
- **Azure Functions Testing**: @azure/functions-test-utils
- **HTTP Mocking**: nock oder similar
- **Performance Testing**: autocannon oder similar

### Potential Blockers
- **Azure OpenAI Rate Limits**: K√∂nnte Tests verlangsamen
- **Database State Management**: Isolation zwischen Tests
- **Environment Configuration**: Test-spezifische Umgebungsvariablen

## Technical Notes

### Test Environment Setup
```bash
# Test-spezifische Umgebungsvariablen
NODE_ENV=test
DATABASE_URL=postgresql://test:test@localhost:5432/testdb
AZURE_OPENAI_ENDPOINT=https://test.openai.azure.com/
AZURE_OPENAI_API_KEY=test-key
AZURE_OPENAI_DEPLOYMENT_NAME=test-deployment
```

### Mock Strategy
- **Azure OpenAI**: HTTP request mocking mit nock
- **Prisma Database**: In-memory SQLite f√ºr Tests
- **Configuration**: Environment variable overrides

### Test Data Management
- **Fixtures**: Realistic test data f√ºr Use Cases, Evaluations, Reviewers
- **Factories**: Dynamische Test data generation
- **Cleanup**: Automatic test data cleanup nach jedem Test

---

**Estimated Total Effort**: 12-16 Stunden  
**Priority**: High (enables confident deployments)  
**Risk Level**: Medium (external service dependencies)
